{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3889dd5",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830b1120",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow\n",
    "%pip install keras\n",
    "%pip install imutils\n",
    "%pip install numpy\n",
    "%pip install opencv-python\n",
    "%pip install matplotlib\n",
    "%pip install scipy\n",
    "%pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5080e802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c9cc69d",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13b37943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import tensorflow.keras.preprocessing.image as Image\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "categories = [\"with_mask\", \"without_mask\"]\n",
    "data = []\n",
    "labels = []\n",
    "cwd = os.path.join(os.getcwd(), \"./dataset\")\n",
    "\n",
    "# Load images & convert them to numeric values\n",
    "for cat in categories:\n",
    "    path = os.path.join(cwd, cat)\n",
    "    for img_name in os.listdir(path):\n",
    "        img_path = os.path.join(path, img_name)\n",
    "        img = Image.load_img(img_path, target_size=(224, 224))\n",
    "        img = Image.img_to_array(img)\n",
    "        img = preprocess_input(img)\n",
    "        \n",
    "        data.append(img)\n",
    "        labels.append(cat)\n",
    "\n",
    "\n",
    "# Convert labels to binary values\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split data into training and test sets\n",
    "(trainX,\n",
    " testX,\n",
    " trainY,\n",
    " testY) = train_test_split(data, labels, test_size=.2, stratify=labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16f7a63",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "981b5b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x3/knkkttzs2pq6kykbhbxr4wjr0000gn/T/ipykernel_55532/1322467963.py:21: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights=\"imagenet\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amir/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 366ms/step - accuracy: 0.8080 - loss: 0.4442 - val_accuracy: 0.8464 - val_loss: 0.3504\n",
      "Epoch 2/5\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.9062 - loss: 0.2595 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 16:45:27.943973: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/Users/amir/anaconda3/lib/python3.11/contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "2024-04-14 16:45:27.966240: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 387ms/step - accuracy: 0.9005 - loss: 0.2730 - val_accuracy: 0.8823 - val_loss: 0.2898\n",
      "Epoch 4/5\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.8750 - loss: 0.2965 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 16:46:27.386587: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-04-14 16:46:27.401620: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 388ms/step - accuracy: 0.8955 - loss: 0.2673 - val_accuracy: 0.8973 - val_loss: 0.2393\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 280ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "LEARNING_RATE = 1e-2\n",
    "EPOCHS = 5\n",
    "BBATCH_SIZE = 32\n",
    "\n",
    "# Generate variations of images to extend the dataset\n",
    "aug = ImageDataGenerator(\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.2,\n",
    "\theight_shift_range=0.2,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "# Build base and head models\n",
    "base_model = MobileNetV2(weights=\"imagenet\",\n",
    "                         include_top=False,\n",
    "                         input_tensor=layers.Input(shape=(224, 224, 3)))\n",
    "\n",
    "head_model = base_model.output\n",
    "head_model = layers.AveragePooling2D(pool_size=(7, 7))(head_model)\n",
    "head_model = layers.Flatten(name=\"flatten\")(head_model)\n",
    "head_model = layers.Dense(128, activation=\"relu\")(head_model)\n",
    "head_model = layers.Dropout(0.5)(head_model)\n",
    "head_model = layers.Dense(2, activation=\"softmax\")(head_model)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=head_model)\n",
    "\n",
    "# Freeze base model layers from being updated during the first training\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Compile the model\n",
    "# opt = Adam(lr=LEARNING_RATE, decay=LEARNING_RATE / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train network's head\n",
    "head = model.fit(\n",
    "\taug.flow(trainX, trainY, batch_size=BBATCH_SIZE),\n",
    "\tsteps_per_epoch=len(trainX) // BBATCH_SIZE,\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tvalidation_steps=len(testX) // BBATCH_SIZE,\n",
    "\tepochs=EPOCHS)\n",
    "\n",
    "# Evaluate network\n",
    "pred_indices = model.predict(testX, batch_size=BBATCH_SIZE)\n",
    "pred_indices = np.argmax(pred_indices, axis=1)\n",
    "model.save(\"face_mask_detector.model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404d180b",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9802d893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x3/knkkttzs2pq6kykbhbxr4wjr0000gn/T/ipykernel_55532/2744930519.py:38: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amir/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:34: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Argument(s) not recognized: {'lr': 0.0001}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# compile our model\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] compiling model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m opt \u001b[38;5;241m=\u001b[39m Adam(lr\u001b[38;5;241m=\u001b[39mINIT_LR, decay\u001b[38;5;241m=\u001b[39mINIT_LR \u001b[38;5;241m/\u001b[39m EPOCHS)\n\u001b[1;32m     62\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39mopt,\n\u001b[1;32m     63\u001b[0m \tmetrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# train the head of the network\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/adam.py:60\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[0;34m(self, learning_rate, beta_1, beta_2, epsilon, amsgrad, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, name, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     45\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     59\u001b[0m ):\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     61\u001b[0m         learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[1;32m     62\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m     63\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[1;32m     64\u001b[0m         clipnorm\u001b[38;5;241m=\u001b[39mclipnorm,\n\u001b[1;32m     65\u001b[0m         clipvalue\u001b[38;5;241m=\u001b[39mclipvalue,\n\u001b[1;32m     66\u001b[0m         global_clipnorm\u001b[38;5;241m=\u001b[39mglobal_clipnorm,\n\u001b[1;32m     67\u001b[0m         use_ema\u001b[38;5;241m=\u001b[39muse_ema,\n\u001b[1;32m     68\u001b[0m         ema_momentum\u001b[38;5;241m=\u001b[39mema_momentum,\n\u001b[1;32m     69\u001b[0m         ema_overwrite_frequency\u001b[38;5;241m=\u001b[39mema_overwrite_frequency,\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     71\u001b[0m     )\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_1 \u001b[38;5;241m=\u001b[39m beta_1\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_2 \u001b[38;5;241m=\u001b[39m beta_2\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py:22\u001b[0m, in \u001b[0;36mTFOptimizer.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution_strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:38\u001b[0m, in \u001b[0;36mBaseOptimizer.__init__\u001b[0;34m(self, learning_rate, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, loss_scale_factor, gradient_accumulation_steps, name, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `decay` is no longer supported and will be ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m     )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument(s) not recognized: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     name \u001b[38;5;241m=\u001b[39m auto_name(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Argument(s) not recognized: {'lr': 0.0001}"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras.applications import MobileNetV2\n",
    "# from tensorflow.keras.layers import AveragePooling2D\n",
    "# from tensorflow.keras.layers import Dropout\n",
    "# from tensorflow.keras.layers import Flatten\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.layers import Input\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "# from tensorflow.keras.preprocessing.image import img_to_array\n",
    "# from tensorflow.keras.preprocessing.image import load_img\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from sklearn.preprocessing import LabelBinarizer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import classification_report\n",
    "# from imutils import paths\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "# INIT_LR = 1e-4\n",
    "# EPOCHS = 20\n",
    "# BS = 32\n",
    "\n",
    "# # construct the training image generator for data augmentation\n",
    "# aug = ImageDataGenerator(\n",
    "# \trotation_range=20,\n",
    "# \tzoom_range=0.15,\n",
    "# \twidth_shift_range=0.2,\n",
    "# \theight_shift_range=0.2,\n",
    "# \tshear_range=0.15,\n",
    "# \thorizontal_flip=True,\n",
    "# \tfill_mode=\"nearest\")\n",
    "\n",
    "# # load the MobileNetV2 network, ensuring the head FC layer sets are\n",
    "# # left off\n",
    "# baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "# \tinput_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# # construct the head of the model that will be placed on top of the\n",
    "# # the base model\n",
    "# headModel = baseModel.output\n",
    "# headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "# headModel = Flatten(name=\"flatten\")(headModel)\n",
    "# headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "# headModel = Dropout(0.5)(headModel)\n",
    "# headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "\n",
    "# # place the head FC model on top of the base model (this will become\n",
    "# # the actual model we will train)\n",
    "# model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "# # loop over all layers in the base model and freeze them so they will\n",
    "# # *not* be updated during the first training process\n",
    "# for layer in baseModel.layers:\n",
    "# \tlayer.trainable = False\n",
    "\n",
    "# # compile our model\n",
    "# print(\"[INFO] compiling model...\")\n",
    "# opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "# \tmetrics=[\"accuracy\"])\n",
    "\n",
    "# # train the head of the network\n",
    "# print(\"[INFO] training head...\")\n",
    "# H = model.fit(\n",
    "# \taug.flow(trainX, trainY, batch_size=BS),\n",
    "# \tsteps_per_epoch=len(trainX) // BS,\n",
    "# \tvalidation_data=(testX, testY),\n",
    "# \tvalidation_steps=len(testX) // BS,\n",
    "# \tepochs=EPOCHS)\n",
    "\n",
    "# # make predictions on the testing set\n",
    "# print(\"[INFO] evaluating network...\")\n",
    "# predIdxs = model.predict(testX, batch_size=BS)\n",
    "\n",
    "# # for each image in the testing set we need to find the index of the\n",
    "# # label with corresponding largest predicted probability\n",
    "# predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# # show a nicely formatted classification report\n",
    "# print(classification_report(testY.argmax(axis=1), predIdxs,\n",
    "# \ttarget_names=lb.classes_))\n",
    "\n",
    "# # serialize the model to disk\n",
    "# print(\"[INFO] saving mask detector model...\")\n",
    "# model.save(\"mask_detector.model\", save_format=\"h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095617fc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
